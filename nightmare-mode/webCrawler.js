// Using Test Driven Development and recursion, build a web crawler. It should:
//       Accept a URL to begin its crawl
//       Recursively follow links
//       Output the URL of crawled pages
//       Accept an optional configuration object as an argument that will effect the default behavior of the crawler.
// Consider configuring:
//       The ability to use getElementsByClassName on any of the pages you visit
//       The ability to output other kinds of information about the page such as number of script tags,
//       distinct attributes, links to external sites, etc.
//       The option to crawl breadth first instead of depth first
//       Limit the depth or breadth of the crawl
//       Set a revisit or politeness policy
//       Refactor the crawler to use web workers

// Web crawler wiki: https://en.wikipedia.org/wiki/Web_crawler
